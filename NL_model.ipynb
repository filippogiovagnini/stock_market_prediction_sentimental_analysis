{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <B3E58761-2785-34C6-A89B-F37110C88A05> /opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <3BD7C270-CE25-3DCF-A6C8-B9D7148F8ADE> /opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model_finbert = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in model_finbert: 109484547\n"
     ]
    }
   ],
   "source": [
    "# Assuming model_finbert is a PyTorch model\n",
    "import torch\n",
    "total_params = sum(p.numel() for p in model_finbert.parameters())\n",
    "print(f'Total number of parameters in model_finbert: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5843, 0.0742, 0.3416],\n",
      "        [0.0092, 0.9704, 0.0204]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "x = [\"DJ index increases!\", \"DJ index to decrease by 10%\"]\n",
    "input_sequence = tokenizer(x, return_tensors=\"pt\", **tokenizer_kwargs)\n",
    "logits = model_finbert(**input_sequence).logits\n",
    "probabilities = F.softmax(logits, dim=-1)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation_utilities import read_csv_from_zip\n",
    "Combined_News_DJIA, DJIA_table, RedditNews, Test_dates = read_csv_from_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_News_DJIA = Combined_News_DJIA.drop(columns=['Date', 'Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 75])\n",
      "torch.Size([2, 75])\n",
      "torch.Size([3, 75])\n",
      "torch.Size([4, 75])\n",
      "torch.Size([5, 75])\n",
      "torch.Size([6, 75])\n",
      "torch.Size([7, 75])\n",
      "torch.Size([8, 75])\n",
      "torch.Size([9, 75])\n",
      "torch.Size([10, 75])\n",
      "torch.Size([11, 75])\n",
      "torch.Size([12, 75])\n",
      "torch.Size([13, 75])\n",
      "torch.Size([14, 75])\n",
      "torch.Size([15, 75])\n",
      "torch.Size([16, 75])\n",
      "torch.Size([17, 75])\n",
      "torch.Size([18, 75])\n",
      "torch.Size([19, 75])\n",
      "torch.Size([20, 75])\n",
      "torch.Size([21, 75])\n",
      "torch.Size([22, 75])\n",
      "torch.Size([23, 75])\n",
      "torch.Size([24, 75])\n",
      "torch.Size([25, 75])\n",
      "torch.Size([26, 75])\n",
      "torch.Size([27, 75])\n",
      "torch.Size([28, 75])\n",
      "torch.Size([29, 75])\n",
      "torch.Size([30, 75])\n",
      "torch.Size([31, 75])\n",
      "torch.Size([32, 75])\n",
      "torch.Size([33, 75])\n",
      "torch.Size([34, 75])\n",
      "torch.Size([35, 75])\n",
      "torch.Size([36, 75])\n",
      "torch.Size([37, 75])\n",
      "torch.Size([38, 75])\n",
      "torch.Size([39, 75])\n",
      "torch.Size([40, 75])\n",
      "torch.Size([41, 75])\n",
      "torch.Size([42, 75])\n",
      "torch.Size([43, 75])\n",
      "torch.Size([44, 75])\n",
      "torch.Size([45, 75])\n",
      "torch.Size([46, 75])\n",
      "torch.Size([47, 75])\n",
      "torch.Size([48, 75])\n",
      "torch.Size([49, 75])\n",
      "torch.Size([50, 75])\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "Combined_News_DJIA_np = Combined_News_DJIA.to_numpy()\n",
    "n = Combined_News_DJIA_np.shape[0]\n",
    "final = torch.tensor([])\n",
    "for i in range(50):\n",
    "    j = 0\n",
    "    x = [char for char in Combined_News_DJIA_np[i].tolist()]\n",
    "    input_sequence = tokenizer(x, return_tensors=\"pt\", **tokenizer_kwargs)\n",
    "    logits = model_finbert(**input_sequence).logits\n",
    "    probabilities = F.softmax(logits, dim=-1).view(1, 75)\n",
    "    final = torch.cat((final, probabilities), dim=0)\n",
    "    print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
